---
title: Assignment 03
author:
  - name: Dakota Alder - dkalder
    affiliations:
      - id: bu
        name: Boston University
        city: Boston
        state: MA
number-sections: true
date: '2025-9-22'
format:
  html:
    theme: cerulean
    toc: true
    toc-depth: 2
  docx: default
date-modified: today
date-format: long
execute:
  echo: false
  eval: false
  freeze: auto
---

## Loading the Dataset

```{python}

#| eval: true
#| echo: true
#| fig-align: center
import pandas as pd
import plotly.express as px
import plotly.io as pio
from pyspark.sql import SparkSession
import re
import numpy as np
import plotly.graph_objects as go
from pyspark.sql.functions import col, split, explode, regexp_replace, transform, when
from pyspark.sql import functions as F
from pyspark.sql.functions import col, monotonically_increasing_id

np.random.seed(42)

pio.renderers.default = "notebook"

# Initialize Spark Session
spark = SparkSession.builder.appName("LightcastData").getOrCreate()

# Load Data
df = spark.read.option("header", "true").option("inferSchema", "true").option("multiLine","true").option("escape", "\"").csv("data/lightcast_job_postings.csv")
df.createOrReplaceTempView("job_postings")

# Show Schema and Sample Data
#print("---This is Diagnostic check, No need to print it in the final doc---")

#df.printSchema() # comment this line when rendering the submission
#df.show(5)
```

## Data Preparation

```{python}
# Casting Salary and Experience Columns
df = df.withColumn("SALARY", col("SALARY").cast("float"))\
  .withColumn("SALARY_FROM", col("SALARY_FROM").cast("float"))\
  .withColumn("SALARY_TO", col("SALARY_TO").cast("float"))\
  .withColumn("MAX_YEARS_EXPERIENCE", col("MAX_YEARS_EXPERIENCE").cast("float"))\
  .withColumn("MIN_YEARS_EXPERIENCE", col("MIN_YEARS_EXPERIENCE").cast("float"))

# Computing Medians for Salary Columns
def compute_median(sdf, col_name):
  q = sdf.approxQuantile(col_name, [0.5], .01)
  return q[0] if q else none

median_from = compute_median(df, "SALARY_FROM")
median_to = compute_median(df, "SALARY_TO")
median_salary = compute_median(df, "SALARY")

print("Medians:", median_from, median_to, median_salary)

#Inputting missing Salaries, but not experience

df = df.fillna({
  "SALARY_FROM": median_from,
  "SALARY_TO": median_to,
  "SALARY": median_salary
})

#Computing Average Salary
df = df.withColumn("Average_Salary", (col("SALARY_FROM") + col("SALARY_TO")/2))

#Selecting Required Columns
exports_cols = [
  "EDUCATION_LEVELS_NAME",
  "REMOTE_TYPE_NAME",
  "MAX_YEARS_EXPERIENCE",
  "Average_Salary",
  "SALARY",
  "LOT_V6_SPECIALIZED_OCCUPATION_NAME"
]
df_selected = df.select(*exports_cols)

#Save to CSV
pdf = df_selected.toPandas()
pdf.to_csv("data/cleaned_data.csv", index=False)

print("Data Cleaning Complete. Rows retained:", len(pdf))
```

```{python}
#Question 1 Code

#Filter out  missing or zero salaries
pdf = df.filter(df["SALARY"] > 0).select("EMPLOYMENT_TYPE_NAME", "SALARY").toPandas()

#Filter out null values from Employment Type Name
pdf = pdf.dropna(subset=["EMPLOYMENT_TYPE_NAME"])

# Clean Employment type names
pdf["EMPLOYMENT_TYPE_NAME"] = pdf["EMPLOYMENT_TYPE_NAME"].apply(lambda x: re.sub(r"[^\x00-\x7F]+", "", x))

#Compute Median Salary by Employment Type
median_salaries = pdf.groupby("EMPLOYMENT_TYPE_NAME")["SALARY"].median()

#Sort Employment Types based on Median Salaries Desc
sorted_employment_types = median_salaries.sort_values(ascending=False).index

#Apply sorted categories
pdf["EMPLOYMENT_TYPE_NAME"] = pd.Categorical(
  pdf["EMPLOYMENT_TYPE_NAME"],
  categories=sorted_employment_types,
  ordered=True
)

#Create box plot with Horizontal grid lines
fig = px.box(
  pdf,
  x="EMPLOYMENT_TYPE_NAME",
  y="SALARY",
  title="Salary Distribution by Employment Type",
  color_discrete_sequence=["blue"],
  boxmode="group",
  points="all",
)

```